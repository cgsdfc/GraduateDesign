% !Mode:: "TeX:UTF-8"
% Author: Zhengxi Tian
% Email: zhengxi.tian@hotmail.com

\chapter*{结论\markboth{结论}{}}\label{ch:conclusion}
\addcontentsline{toc}{chapter}{结论}

\section{总结}\label{sec:conclusion}
% -- Related Work -- %
本文对生成式对话领域的模型，数据集和指标进行了一次深入考察。
我们首先介绍了生成式对话领域的兴起过程中一些重要的模型，比如
Ritter等人的SMT模型\upcite{Ritter11}，
Sordoni等人的DCGM模型\upcite{DCGM}和Vinyals等人的
NCM模型\upcite{GoogleChatbot}。
接着，在相关工作中，我们介绍了生成式模型的定义，
模型的核心组件RNN，以及几种常见的生成式模型，包括最简单的RNN语言模型，
广为流行的Seq2Seq框架和多层编解码器HRED。
我们还介绍了本领域用到过的一些指标，包括基于词重叠的BLEU，
ROUGE和METEOR，基于词嵌入的Average，Extrema和Greedy，
衡量概率语言模型性能的困惑度，以及专门为生成式对话设计的ADEM和RUBER。
最后，我们介绍了生成式对话文献中常见的数据集，
包括Twitter Dialogue Corpus，Ubuntu Dialogue Corpus和
OpenSubtitles等等。

% -- Method -- %
在众多模型，数据集和指标中，我们选择了Serban等人在\cite{VHRED}
中使用的三个模型HRED，LSTM和VHRED。
这三个模型有着成熟的实现，易于其他人复现我们的实验。
在数据集方面，我们选择了公开且易得的，代表了不同领域的三个数据集，
分别是Ubuntu Dialogue Corpus，OpenSubtitles和LSDSCC。
这些数据集的领域都是文献中常见的。
在指标方面，我们尽可能涵盖了对话领域使用过或者提出的指标，
在配置方面与\cite{HowNot}大致对齐。
实验的主要工作主要是：
\begin{enumerate}
    \item 在多个数据集上训练多个模型。
    \item 在训练结果上运行多个评价指标。
    \item 对指标进行多种数据分析。
\end{enumerate}
我们的实验数据是由多个模型和数据集的组合在不同指标上的系统层面和句子层面
得分，以及这些模型输出的响应组成的。
由于时间关系，我们只分析了得分的数据。

我们探索了系统层面和句子层面的实验结果。
系统层面得分是是对一个模型在一个数据集上的表现的粗粒度考察，
它可能掩盖了一些事实，
但是方便我们综合考察模型、数据集和指标三者的整体关系。
我们参考\cite{HowNot}，将指标的数据进行分组，
并以此组织所有的分析。我们把BLEU的N取不同值的指标分为一组，
把ROUGE的所有变形分为一组，把词嵌入的指标和ADEM分为一组，
把剩下的METEOR，Distinct-N和句子长度归到一组。
分组的最初目的是便于合理利用有限的页面空间，
但是它也让数据分析更加有条理。

各个模型的系统层面得分随着数据集的变化和指标的变化有较大差异，
比较稳定的是同一个数据集上各个模型的排名，
一般HRED和VHRED比LSTM优秀，
然而有时优势不太明显，有时会出现LSTM反超HRED和VHRED的情况。
模型在Ubuntu Dialogue Corpus上的各项指标通常更好，
但是有时候另外两个数据集的某些得分会反超。
从附录~\ref{ch:dataset_system_dist}~和附录~\ref{ch:model_system_dist}~可以发现，数据集和模型对得分都有影响，
从大体上看，HRED和VHRED优于LSTM，Ubuntu Dialogue Corpus的得分
高于其他数据集，但是这不是绝对的，实验数据中存在许多反例。
我们认为，除了实验过程本身带来的噪音外，
主要的原因是数据集的特征变化太大，
模型无法完全将一个数据集上的性能迁移到另一个数据集上。
而且，
实验中的指标对生成式对话的适用程度不同，
指标形成了集群现象，不同集群之间一致性很低，
给评价造成了混乱。

我们在句子层面的分析主要采取得分的单变量概率分布的形式，
从不同指标的分布图像中验证了指标之间的集群现象。
指标的集群反映了提取相同特征的指标很可能有相似的行为，
不管它们如何使用这些特征。
在这些指标的集群中，我们发现图像大致有两类：
\begin{enumerate}
    \item 基于词嵌入的指标的图像接近高斯分布。
    \item 基于词重叠的指标的图像是不对称的双峰曲线，
    大量句子集中在均值附近的很小范围。
\end{enumerate}
我们假设在大量句子上的人类评价将接近高斯分布，
从而认为分布接近高斯分布的指标是更好的选择。
我们基于句子得分分布的分析发现了指标在大量句子上的统计规律，
从统计的角度验证了词嵌入指标比词重叠指标更适合本领域\upcite{HowNot}。

我们的实验有些不完善的地方。
所有数据集上的LSTM模型的门单元应该统一使用LSTM；
解码时我们使用了随机取样，结果发现响应中有很多语法错误，
使用集束搜索可以产生语法错误较少的响应。
我们没有针对特定数据集做参数的调优，
导致模型在有些数据集上的表现没有达到最优。
我们也没有像\cite{VHRED}那样用预训练的HRED初始化VHRED的参数，
结果VHRED的性能没有达到最优。
我们将汲取经验教训，尽量减少实验程序带来的噪音。

\section{展望}\label{sec:future_work}
