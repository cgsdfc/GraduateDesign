1.修复Jiwei的代码库，可展开2周
2.修复Serban的代码库。
3.收集数据集，下载速度很慢，wget和curl均无法实现断点下载。实现了get_chunk
4.安装docker和nvidia-docker
5.修复Adem指标模型，AutoTuring
6.修复Rubber指标模型，ref和unref
7.抢占式训练和训练进度监控方法。
8.修复Rubber。
9.从Seq2SeqChatbots中获得大量模型的情报。
10.收集METEOR指标时发现了大量的MT指标，均找到代码实现。
11.发现了Cornell数据集，元信息丰富，自带Turn Taking，规模中等，格式json，包括parliament，supreme，movie，reddit-small，tennis。reddit本身是多个subreddit组成的巨大的数据集。
12.在Opensub上训练Jiwei的模型，训练了一周还是只有无意义的输出。老师叫我不要顾着复现模型。
13.在Ubuntu上训练Serban的模型，一周，三个模型的PPL收敛到30,40和50，输出比较有意义。
14.在OpenSubTitles上训练Serban的模型，使用dialogue_3_6，
