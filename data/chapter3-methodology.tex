% !Mode:: "TeX:UTF-8"
% Author: Zhengxi Tian
% Email: zhengxi.tian@hotmail.com

\chapter{研究方法}\label{ch:method}

% -- 简要说明实验框架。并不复杂，一图足矣。
% 详细说明数据集的统计数据，模型的超参数，训练参数，指标实现的来源，
% 指标的超参数。这些属于Training Procedure或者Experiment的内容。
% 因为是本科毕设，写verbose一些也没关系。
\section{指标测评框架}\label{sec:eval_framework}
我们的实验主要涉及在多个数据集上训练多个模型，然后用多种指标去测量这些系统的句子层面得分和系统层面得分。
表~\ref{tab:experiment_triples}~展示了实验所使用的模型，数据集和指标。
% -- Math & Figure
如图~\ref{fig:framework}~所示，我们的实验首先从对每一个模型$m$和数据集$d$的组合$(m, d) \in M \times D$在训练集上进行训练，
并让训练好的$(m, d)$在测试集上解码产生响应$r$，然后再用每一个指标$s \in S$去给$r$在句子层面和系统层面上打分，分别得到$\lambda_{u}$和$\lambda_{s}$。实验的最终结果是获得一个5元组$(m, d, e, \lambda_{u}, \lambda_{s})$，表示在数据集$d$上训练的模型$m$在指标$s$的评价下所得的句子层面得分$\lambda_u$和系统层面得分$\lambda_s$。


%本章将详细介绍模型的超参数，训练流程，数据集预处理等实验细节。
\begin{table}[H]
    \centering
    \caption{实验对象一览}
    \label{tab:experiment_triples}
    \begin{tabular}{|r|m{0.6\textwidth}|}
        \hline
        模型 & HRED，LSTM，VHRED \\
        \hline
        数据集 & Ubuntu，OpenSubtitles，LSDSCC \\
        \hline
        指标 & BLEU，ROUGE，METEOR，Vector-Average，
        Vector-Extrema，Greedy-Matching，
        ADEM，PPL，Distinct-N \\
        \hline
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figure/drawio/eval_v3.pdf}
    \caption{实验框架}
    \label{fig:framework}
\end{figure}

\section{模型超参数设置}\label{sec:model_hparams}
% ------ Model setup ----------- %
在模型超参数方面，我们的设置大致和\cite{VHRED}相同。
我们用Adam\upcite{AdamOpt}来优化所有模型，
batch\_size统一设为20。
% -- Dimension of Word Embeddings -- %
我们在Ubuntu上使用维度是300的词嵌入，
在OpenSubtitles和LSDSCC上使用维度是400的词嵌入。
% -- Hidden Units of Utterance Encoder -- %
HRED和VHRED的句子编码器（Utterance Encoder）
在Ubuntu上使用500个隐藏单元，
在OpenSubtitles和LSDSCC上使用1000个隐藏单元
\footnote{这里的LSTM模型是一个语言模型，所以它既没有编码RNN，
也没有上下文RNN，只有解码RNN。}。
% -- Hidden Units of Context Encoder -- %
HRED和VHRED的上下文编码器（Context Encoder）
在所有数据集上都使用1000个隐藏单元。
% -- Hidden Units of Utterance Decoder -- %
不同模型的句子解码器（Utterance Decoder）
在不同数据集上各有不同，
如表~\ref{tab:utterance_decoder_hidden_units}~所示。
我们根据数据集的特点来设置不同RNN的隐藏单元数目，
通常在样本数多或者词汇表大的数据集上训练时，
模型的隐藏单元数目会更多。

\begin{table}[H]
    \centering
    \caption{句子解码器的隐层状态单元数目}
    \label{tab:utterance_decoder_hidden_units}
    \begin{tabular}{llll}
        \toprule
        & HRED & LSTM & VHRED \\
        \midrule
        LSDSCC & 1000 & 2000 & 1000 \\
        OpenSubtitles & 1000 & 2000 & 1000 \\
        Ubuntu & 500 & 2000 & 500 \\
        \bottomrule
    \end{tabular}
\end{table}

% -- Direction of Utterance Encoder -- %
Ubuntu上的模型的句子编码器都使用了单向RNN，
而OpenSubtitles和LSDSCC上的模型的句子编码器则使用双向RNN。
% -- Gate Type of Utterance & Context Encoder -- %
所有模型的句子编码器和上下文编码器（如果有）都使用GRU作为门单元。
% -- Gate Type of Decoder -- %
句子解码器的门单元类型如表~\ref{tab:utterance_decoder_gate_types}~所示
\footnote{由于失误，OpenSubtitles和LSDSCC上的LSTM模型的解码器都没有使用LSTM门单元，不过它们仍然是语言模型。}。
\begin{table}[H]
    \centering
    \caption{句子解码器的门单元类型}
    \label{tab:utterance_decoder_gate_types}
    \begin{tabular}{llll}
        \toprule
        & HRED & LSTM & VHRED \\
        \midrule
        LSDSCC & LSTM & GRU & GRU \\
        OpenSubtitles & LSTM & GRU & GRU \\
        Ubuntu & LSTM & LSTM & LSTM \\
        \bottomrule
    \end{tabular}
\end{table}

所有的模型都在一台GeForce GTX TITAN X上训练了至少1周。
模型收敛时的困惑度如表~\ref{tab:converged_perplexity}~所示。
\begin{table}[H]
    \centering
    \caption{}
    \label{tab:converged_perplexity}
    \begin{tabular}{llll}
        \toprule
        & HRED & LSTM & VHRED \\
        \midrule
        LSDSCC & & &  \\
        OpenSubtitles & & &  \\
        Ubuntu & & &  \\
        \bottomrule
    \end{tabular}
\end{table}

与\cite{VHRED}不同的是，我们没有用预训练的HRED的参数来初始化对应的VHRED。
从实验结果来看，从零开始训练的VHRED也能达到和HRED相匹配的性能。
所有的模型都使用了梯度剪裁，阈值为1。
所有模型在Ubuntu上的学习率为0.0002，
在OpenSubtitles和LSDSCC上的学习率为0.0001。
在解码时，我们使用随机取样。

\section{数据集预处理}
\label{sec:dataset_proprecessing}
我们使用的Ubuntu Dialogue Corpus直接来自Serban等人的项目hed-truncated
\footnote{\url{https://github.com/julianser/hed-dlg-truncated.git}}，没有经过任何额外处理。
我们从Li等人的项目Neural-Dialogue-Generation中获取了经过预处理的OpenSubtitles数据
\footnote{\url{https://github.com/jiweil/Neural-Dialogue-Generation.git}}（他们称其为OpenSubData）。
对OpenSubData作了如下处理：
\begin{enumerate}
    \item 将其从整数的下标形式还原为字符串的单词形式；
    \item 将其字典文件\texttt{movie\_25000}转化为下标从0开始的
    pickle\footnote{pickle是一个Python特有的序列化格式}格式。
    \item 使用Serban等人的\texttt{convert\_text2dict.py}脚本，将训练集，测试集和开发集均转换为pickle格式；
    \item 选用OpenSubData中的3轮对话，句子最短长度为6的dialogue3\_6格式作为实际使用的数据集；
    \item 从测试集随机取样1\%的样本作为正式使用的数据集。
\end{enumerate}

LSDSCC也是一个经过预处理的数据集\footnote{\url{https://drive.google.com/file/d/1nbpbnhwNP14xAc4SAc1 NN5lvEr01dQb/view?usp=sharing}}。
由于它的词汇数量多达50K，为了使内存不至于溢出，我们将其词汇表裁剪至35000个最常见的单词。
此外，由于我们只使用单个参考的指标，因此对LSDSCC的测试集中的多个参考，我们只取第一个参考。
剩下的处理过程类似OpenSubData的处理。
\begin{table}
    \centering
    \caption{训练集的统计数据}
    \label{tab:training_set_statistics_T}
    \begin{tabular}{lllll}
        \toprule
        数据集 & 词汇数量 & 样本数量 & 单词数量 & 轮数 \\
        \midrule
        Ubuntu & 20000 & 448833 & 45697699 & 多轮 \\
        OpenSubtitles & 23876 & 11771393 & 379346841 & 3 \\
        LSDSCC & 35008 & 738095 & 32355628 & 1 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}
    \centering
    \caption{训练集的统计数据}
    \label{tab:training_set_statistics}
    \begin{tabular}{llll}
        \toprule
        & Ubuntu & OpenSubtitles & LSDSCC \\
        \midrule
        词汇数量 & 20000 & 23876 & 35008 \\
        样本数量 & 448833 & 11771393 & 738095 \\
        单词数量 & 45697699 & 379346841 & 32355628 \\
        轮数 & 多轮 & 3 & 1 \\
        \bottomrule
    \end{tabular}
\end{table}


\section{指标配置}\label{sec:metric_config}

\section{本章小结}\label{sec:method_conclusion}
