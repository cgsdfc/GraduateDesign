% !Mode:: "TeX:UTF-8"
% Author: Zhengxi Tian
% Email: zhengxi.tian@hotmail.com

\chapter{绪论}\label{ch:绪论}

\section{课题研究背景}\label{sec:课题研究背景}
% Task-Oriented and Chat-Oriented.
早期的对话系统的用途主要是帮助用户用自然语言使用某个系统，比如技术支持（Technical Support），预订机票、预订餐馆的座位、查询航班等。这一类系统又被称为任务导向的系统，其实现技术包括关键词匹配、规则和模板以及对话状态追踪等等，往往需要大量人工标注的数据。这些系统往往只能处理特定领域内的对话，不能回答开放性问题，用途局限于特定领域\upcite{DBLP:journals/corr/SerbanLCP15,DBLP:journals/corr/VinyalsL15,DBLP:conf/acl/ShangLL15}。

随着在线聊天的盛行，社交媒体和互联网论坛积累了大量的聊天语料数据，具有代表性的社交媒体和论坛有Twitter，Reddit和微博。大量的数据使人们可以构建数据驱动的(Data-Driven)，开放领域(Open-Domain)的对话系统\upcite{Ritter:2011:DRG:2145432.2145500}。这种系统能根据对话的上下文和用户的提问产生语义相关的回答，用途有娱乐、语言学习工具和陪伴\upcite{DBLP:conf/aaai/SerbanSBCP16}等等。该领域主要考察二人对话，两人聊天的历史记录称为上下文（context），记为$c$；当前说话的人说出的话语称为消息（message），记为$m$；另外一个人对该消息的回复称为响应（response），记为$r$。$c,m,r$三者的关系如图~\ref{fig:context_message_response}所示。系统的输入是$c,m$，输出是$r$，也就是把对话的上下文和消息映射为响应，这个问题被称为对话响应生成（Conversation Response Generation）。

\begin{figure}[H]
    \includegraphics[width=0.6\textwidth]{figure/context_message_response.png}
    \centering
    \caption{上下文，消息和响应的关系\upcite{DBLP:journals/corr/SordoniGABJMNGD15}}
    \label{fig:context_message_response}
\end{figure}

% Retrieval and Generative.
对话系统又可以分为生成式对话系统（Generative）和检索式对话系统（Retrieval）\upcite{DBLP:journals/corr/SerbanLCP15}。它们的区别在于：生成式系统以输入句子为条件，把条件概率最大的句子作为输出。
由于搜索空间是一个全部句子，过于庞大，在实际中通常采用某种启发式搜索方法，如Beam Search，Greedy Search和Random Sample。
设$X$为输入句子，$Y$为输出句子，$U$是全部句子的集合，生成式模型从输出获取输出句子的数学表述为：
\begin{align}
    Y = \text{argmax}_{Y\in U} \left(p(Y|X)\right)
\end{align}

检索式系统根据输入句子从一个数据库$D$中检索输出句子。$D$通常足够大，使得输出句子不容易重复。
系统通过某种打分机制$Score(X, Y)$对数据库中的候选句子进行打分，并把得分较高的候选作为输出：
\begin{align}
    Y = \text{argmax}_{Y\in D} Score(Y, X)
\end{align}
可见，生成式系统和检索式系统的根本区别在于获得输出句子的机制不同。
在实际环境中，这两种方法各有千秋，通常将它们作为模型联合体（Model Ensemble）使用\upcite{DBLP:journals/corr/SongYLZZ16}。

生成式对话系统最早在2011年开始被研究。
Ritter等人率先用统计机器翻译（Statistical Machine Translation，SMT）的方法\upcite{Ritter:2011:DRG:2145432.2145500}解决响应生成问题。他们没有考虑上下文，而是把一个消息直接翻译为响应。Sordoni等人首次把神经网络用于响应生成，用神经网络对SMT输出的响应进行重现排序\upcite{DBLP:journals/corr/SordoniGABJMNGD15}。他们的模型属于在机器翻译中非常有效的编码器-解码器架构（Encoder-Decoder），对输入的上下文和消息进行词袋化（Bag-of-Word）后，用一个前馈神经网络（Feed-Forward Neural Network）进行编码，再用一个朴素的\footnote{称其为朴素的是因为它没有使用LSTM或者GRU，仅用了$\sigma$激活函数。}（Recurrent Neural Network，RNN）构成的语言模型（Language Model，LM）\upcite{DBLP:conf/interspeech/MikolovKBCK10}进行解码，根据上下文和消息的特征组合方式不同，他们提出了三个模型：RLM，DCGM-1和DCGM-2。Sutskever等人于2014年提出了基于RNN的编解码器，也就是序列到序列架构（Seq2Seq）\upcite{DBLP:conf/nips/SutskeverVL14}。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figure/Seq2Seq.png}
    \caption{Seq2Seq架构图\upcite{DBLP:conf/nips/SutskeverVL14}}
    \label{fig:Seq2Seq}
\end{figure}

\section{课题研究意义}\label{sec:课题研究意义}
这一节讲我们的课题如何能帮助人们更好的使用现有自动化指标（Use it wisely），
避免出现这样一种情况：比如BLEU在Liu说它和人类评价不相关之前，大家都用它；Liu说了不行之后，
大家就都不用了。我们的研究提供了这样一种方法，让你知道哪些指标可以用，该怎么用。
我们的研究还有助于自动化指标的开发。一个好的自动化指标，我们认为，除了要和人类评价相关性高之外，
还要具有比较光滑和平稳的分布，在理想状态下应该接近正态分布。
最后，通过观察一个模型在不同数据集上的指标分布相关性，
我们的方法可以客观全面的评价一个模型在不同数据集上的表现，从而使模型的鲁棒性大大增强。

\section{课题研究内容}\label{sec:课题研究内容}
这一节讲我们对问题的描述。把问题进行一个定性，就说是：对现有指标，模型和数据集的一个细致的考察，
目的是捕捉可能存在的一致性或者不一致性，从中得到支持我们的结论的证据。

\section{论文组织结构}\label{sec:论文组织结构}
本文剩下的组织结构是这样的：第二章《相关工作》总结了领域内对自动化指标的使用和研究现状，主要列举了生成式对话系统最为常用的
几个自动化指标：BLEU，困惑度（Perplexity，PPL），基于词嵌入的指标（Embedding Based）和研究者为了衡量对话的多样性而提出的
指标，如DeltaBLEU，ADEM，RUBER和LSDSCC等。本文的第三章《研究方法》介绍了本次实验所使用的框架，包括对涉及到的模型、数据集和
指标的简介，框架的运行流程，以及实验设计的数学依据。本文的第四章《实验结果与讨论》详细的介绍了所有实验的细节，包括模型训练的参数，数据集的预处理，
最重要的是，实验数据的分析和呈现。我们将从数据中分析得出几个重要的结论。最后一章是《总结》，我们总结实验所得出的结论并给出了
生成式模型的自动化指标的几个发展方向。
