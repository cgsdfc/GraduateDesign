% Hack to fix the section & chapter numbering
%\setcounter{chapter}{5}
%\setcounter{section}{0}
\chapter*{结论}\label{ch:conclusion}
\addcontentsline{toc}{chapter}{结论}

\section*{总结}\label{sec:conclusion}

% -- Related Work -- %
本文对生成式对话领域的模型，数据集和指标进行了一次深入考察。
本文首先介绍了生成式对话领域的兴起过程中一些重要的模型，比如
Ritter等人的SMT模型\upcite{Ritter11}，
Sordoni等人的DCGM模型\upcite{DCGM}和Vinyals等人的
NCM模型\upcite{GoogleChatbot}。
接着，在相关工作中，本文介绍了生成式模型的定义，
模型的核心组件RNN，以及几种常见的生成式模型，包括最简单的RNN语言模型，
广为流行的Seq2Seq框架和多层编解码器HRED。
本文还介绍了本领域用到过的一些指标，包括基于词重叠的BLEU，
ROUGE和METEOR，基于词嵌入的Average，Extrema和Greedy，
衡量概率语言模型性能的困惑度，以及专门为生成式对话设计的ADEM和RUBER。
最后，本文介绍了生成式对话文献中常见的数据集，
包括Twitter对话数据集，Ubuntu对话数据集和OpenSubtitles等等。

% -- Method -- %
在众多模型，数据集和指标中，本文选择了Serban等人在文献\cite{VHRED}
中使用的三个模型HRED，LSTM和VHRED。
这三个模型有着成熟的实现，易于其他人复现本文的实验。
在数据集方面，本文选择了公开的，代表了不同领域的三个数据集，
分别是Ubuntu对话数据集，OpenSubtitles和LSDSCC。
%这些数据集的领域都是文献中常见的。
在指标方面，本文尽可能涵盖了对话领域使用过或者提出的指标，
在配置方面与文献\cite{HowNot}大致对齐。
实验的主要工作是：
\begin{enumerate}
    \item 在多个数据集上训练多个模型。
    \item 在训练结果上运行多个评价指标。
    \item 对指标进行多种数据分析。
\end{enumerate}
实验数据包括多个模型和数据集的组合在不同指标上的得分， 以及这些模型输出的响应。
由于时间关系，本文只分析了得分的数据，把分析模型的输出作为今后的工作。

本文探索了系统层面和句子层面的得分。
系统层面得分是是对一个模型在一个数据集上的表现的粗粒度考察，
它可能掩盖了一些事实，
但是便于综合考察模型、数据集和指标三者的整体关系。
以文献\cite{HowNot}为参考，本文将指标进行了分组，并围绕各组指标进行分析。
具体分组是：
把BLEU的N取不同值的指标分为一组，
把ROUGE的所有变形分为一组，把词嵌入的指标和ADEM分为一组，
把剩下的METEOR，Distinct-N和句子长度归到一组。

各个模型的系统层面得分随着数据集的变化和指标的变化有较大差异，
比较稳定的是同一个数据集和指标上各个模型的排名，
一般HRED和VHRED比LSTM好，
有时优势不太明显，有时会出现LSTM反超的情况。
模型在Ubuntu对话数据集上的各项指标通常更好，
但是有时候某些指标在另外两个数据集上的得分会反超。
从附录~\ref{ch:dataset_system_dist}~可以发现，
数据集和模型对得分都有影响，
从大体上看，HRED和VHRED优于LSTM，Ubuntu对话数据集的得分
高于其他数据集，但是这不是绝对的，实验数据中存在许多反例。
除了实验过程本身带来的噪音外，
主要的原因是数据集的特征变化太大，
模型无法完全将一个数据集上的性能迁移到另一个数据集上。
而且，实验中的指标形成了集群现象，不同集群之间一致性很低，
给评价造成了混乱。

在句子层面的分析主要采取单变量概率分布的形式，
从不同指标的分布图像中验证了指标之间的集群现象。
指标分布的集群现象反映了提取相同特征的指标很可能有相似的分布，
不管它们如何使用这些特征。
指标分布的图像大致可分为两类：
\begin{enumerate}
    \item 基于词嵌入的指标的图像接近高斯分布。
    \item 基于词重叠的指标的图像是不对称的双峰曲线， 大量句子集中在均值附近很小的范围。
\end{enumerate}

\section*{展望}\label{sec:future_work}
在实验结论的基础上，
本章对生成式对话领域的模型，数据集以及指标提出几点展望。
% -- Model -- %
在模型方面， 尽管Seq2Seq框架在机器翻译领域取得成功，
但是在更加困难的对话生成领域，它的表达力遇到了瓶颈。
因此，本文建议尝试新的模型体系结构。
Transformer框架\upcite{Transformer}是一种在大规模语料库上预训练的，
能根据特定任务微调的语言模型。
基于Transformer框架的模型在多项自然语言处理任务中取得了目前最高水平，
将其应用到生成式对话领域有望提升模型的性能。
其他值得尝试的体系结构有对抗生产网络和强化学习，
Li等人在这方面已经获得了意义重大的进展\upcite{deep_RL,Adversarial}。
另一方面，本文建议在模型中添加额外的特征，比如感情色彩\upcite{ECM}，
主题词\upcite{Topic_Aware}和对话者身份信息\upcite{persona}等等。
添加额外特征能使模型的输出在这些特征上具有一致性，从而提高人类评价的得分。

% -- Dataset -- %
在数据集方面，通过互联网收集的数据集容易引入多方面的噪音。
事实上，
这些数据集的特点和人类在互联网这种匿名平台的表现有密切联系。
由于在这种平台上人们的言论没有什么限制，对话的话题非常多样，
而且语言风格，语法习惯和感情色彩和具体的用户与具体的对话有关，
这就使得数据集具有很高的熵。
从概率的角度，
数据集的样本分布可以看作是非常多个随机变量的叠加，
如果这些随机变量都是独立同分布的话，
整个数据集的样本分布就趋向于高斯分布。
面对复杂的数据集，本文建议使用概率统计学工具分析它在
多个方面的分布情况，例如情感分布，对话轮数分布等等。
了解数据集的统计特征有助于理解在这个数据集上训练模型的难度。
% how to explain the normal-like distribution?

% -- Metric -- %
在指标方面，本文的实验大体上验证了文献\cite{HowNot}的结论。
在此基础上，本文提出了一个问题：什么样的对话才是好的对话？
这是一个重要的问题，因为它不仅指导着指标的构建，还决定了模型优化的方向。
这个问题的答案不是“语义相关性高”或者“n-gram多样性高”
这些片面的特征，尽管它们可能是答案的一部分。
这个问题可能难以回答，甚至没有普适性的答案，
因为人类的对话是在自然环境和社会环境中演化出来的一种语言现象，
它根据不同场合和参与者的变化而变化的，非常复杂。

从实用的角度，
可以通过实验发现在某些数据集上好的对话应有的特征。
直观的来说，
在Ubuntu对话数据集上，好的对话应该和具体的技术话题
有较高的相关性，因为这个数据集上的对话以“提问-解决问题”为主，
好的对话应该能帮助人们解决问题；
而在Twitter对话数据集上，好的对话应该考虑情感因素，
关注主题的同时又具有一定的多样性，
因为人们在Twitter上主要发布个人的状态信息，
经常带有感情色彩，
而且期望从响应中看到相同的话题或者新奇的事物；
在LSDSCC上，好的对话应该能对特定的电影发表中肯的评价，
因为在Reddit的电影板块上，人们主要发表对电影的点评，
希望和看过相同或者类似电影的人一起讨论，
人们虽然有时候会发表极端的评价，
但是不希望总是看到极端的评价，
所以模型的评价应该中肯，
最好带有一点个性化看法。
不妨给“什么样的对话才是好的对话”加上“在某个数据集上”的限定词，
从某个数据集中发现最受欢迎的对话的模式，
然后设计出能捕获这些模式的指标，
并用它一致的评价在该数据集上训练的模型的表现。
具体来说，本文把“设计出和人类评价相关度高的指标”这一任务分解为若干个小任务：
\begin{enumerate}
    \item 把问题限制在某个数据集上。
    \item 找出这个数据集上人类评价高的对话具有的特征。
    \item 设计出能准确捕获这些特征的指标。
    \item 用人类评价验证指标在对应数据集上的有效性。
\end{enumerate}

必须指出的是，第二步和第三步具有很大的难度。
第二步一般需要人类评价员对数据集的样本打分，
这导致带有人类评价的样本数量非常受限，
这对指标的泛化能力提出了很高的要求\upcite{ADEM}。
第三步涉及的特征比较抽象，对指标的建模能力提出了很高的要求。

最后，本文建议在模型的目标函数中考虑人类需求的满足程度。
面向任务的对话系统的功能是用对话的形式帮助人完成任务，
而生成式对话系统的功能是娱乐、语言学习和陪伴。
然而这些功能不乏替代品：
现代人从来不缺少娱乐，语言学习也有成熟的产业链，
而亲人和爱人的陪伴是公认的最好的陪伴。
生成式系统只有满足人们多种多样的需求，才能在竞争中获胜。
人们在对话方面的需求是多种多样的：
有的人通过对话获取信息，
有的人通过对话排解情绪，
有的人通过对话寻找快乐。
虽然需求分析比较接近应用，
但是理论和应用相结合能加快研究成果向实际应用转化，
也能使研究本身从应用的反馈中受益。
综上所述，本文建议把人类需求的满足程度作为模型的目标函数之一，并设计相关的指标加以衡量。
相信考虑了人类需求的模型将更受人类评价的青睐。
